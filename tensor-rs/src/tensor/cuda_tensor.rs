
// There are several rust library built around cuda:
// 1. There are nightly rust support and ptx support to write cuda kernel in rust.
// 2. There are cuda library wrapper for cuda ffi
// 3. There are high leverl wrapper for cuda.
//
// https://github.com/rust-cuda is the ffi wrapper
// https://github.com/bheisler/RustaCUDA is a high level wrapper, based on cuda-sys from https://github.com/rust-cuda
// https://github.com/denzp/rust-ptx-builder is used in build.rs to compile rust to ptx
// https://github.com/spearow/juice rely on a generated ffi, which is generated by a unknonw process!!!.

use cuda11_cudart_sys::{self, cudaMalloc, cudaStreamCreate, cudaMemcpy, cudaStreamSynchronize, cudaFree, cudaStreamDestroy, cudaMemcpyKind, check_cuda_status};

pub struct CudaTensor {
    device_data: *mut f32,
    dim: Vec<usize>,
    mm_data: Vec<f32>,
}

impl CudaTensor {
    fn new() -> CudaTensor {
        CudaTensor {
            device_data: std::ptr::null_mut(),
            dim: Vec::new(),
            mm_data: Vec::new(),
        }
    }
    fn new_raw(data: &[f32], shape: &[usize]) -> CudaTensor {
        
        let mut device_data: *mut f32 = std::ptr::null_mut();
        let elems: usize = shape.iter().product();
        if elems != data.len() {
            panic!();
        }

        unsafe {
            //println!("cudaMalloc");
            check_cuda_status(cudaMalloc(&mut device_data as *mut _ as *mut _,
                                         std::mem::size_of::<f32>()*elems));
            //println!("cudaMemcpy");
            cudaMemcpy(device_data as *mut _,
                       data.as_ptr() as *mut _,
                       std::mem::size_of::<f32>()*elems,
                       cudaMemcpyKind::cudaMemcpyHostToDevice);
        }
            
        CudaTensor {
            device_data: device_data,
            dim: shape.to_vec(),
            mm_data: data.to_vec(),
        }
    }

    pub fn new_move(data: Vec::<f32>, shape: Vec::<usize>) -> CudaTensor {
        unimplemented!();
    }
        
    fn _sync(&mut self) {
        let elems: usize = self.dim.iter().product();
        
        unsafe {
            cudaMemcpy(self.mm_data.as_mut_ptr() as *mut _,
                       self.device_data as *mut _,
                       std::mem::size_of::<f32>()*elems,
                       cudaMemcpyKind::cudaMemcpyDeviceToHost);
        }
    }

    // 
    // as_tensor
    // as_strided
    // from_ndarray
    // zeros
    pub fn zeros(size: &[usize]) -> CudaTensor {
        let cap = size.iter().product();
        CudaTensor::new_raw(&vec![0.; cap], size)
    }
    // zeros_like
    pub fn zeros_like(&self) -> CudaTensor {
        let cap = self.dim.iter().product();
        CudaTensor::new_raw(&vec![0.; cap], &self.dim)
    }

    // ones
    pub fn ones(size: &[usize]) -> CudaTensor {
        let cap = size.iter().product();
        CudaTensor::new_raw(&vec![1.; cap], size)
    }
    // ones_like
    pub fn ones_like(&self) -> CudaTensor {
        let cap = self.dim.iter().product();
        CudaTensor::new_raw(&vec![1.; cap], &self.dim)
    }
    // arange
    pub fn arange(end: usize) -> CudaTensor {
        let mut d: Vec<f32> = vec![0.; end];
        for i in 0..end {
            d[i] = i as f32;
        }
        CudaTensor::new_raw(&d, &vec![1])
    }
    // range
    // linspace
    // logspace
    // eye
    pub fn empty(shape: &[usize]) -> CudaTensor {
        let mut device_data: *mut f32 = std::ptr::null_mut();
        let elems: usize = shape.iter().product();

        unsafe {
            //println!("cudaMalloc");
            check_cuda_status(cudaMalloc(&mut device_data as *mut _ as *mut _,
                                         std::mem::size_of::<f32>()*elems));
        }
            
        let mut ret = CudaTensor {
            device_data: device_data,
            dim: shape.to_vec(),
            mm_data: vec![0.; elems],
        };
        ret._sync();
        ret
    }
    // empty_like
    // empty_stided
    // full
    // full_like
    // quantize_per_tensor
    // quantize_per_channel
    // 

    /// Create a tensor filled with the same value d
    ///
    /// ```
    /// # use tensor_rs::tensor::gen_tensor::*;
    /// let m1 = GenTensor::<f64>::fill(1., &vec![3,5,2]);
    /// ```
    pub fn fill(d: f32, shape: &[usize]) -> CudaTensor {
        let elems: usize = shape.iter().product();
        let d: Vec<f32> =  vec![d; elems];

        CudaTensor::new_raw(&d, shape)
    }
    /// assign a row.
    pub fn from_record(&mut self, row: usize, record: &[f32]) -> Result<(), ()> {
        unimplemented!();
    }

    /// Right dimension changes fastest.
    /// Right dimension has the stride 1.
    ///
    /// ```
    /// # use tensor_rs::tensor::gen_tensor::*;
    /// let m1 = GenTensor::<f64>::new_raw(&vec![0.; 3*5*2], &vec![3,5,2]);
    /// assert_eq!(m1.stride(), vec![10,2,1]);
    /// ```
    pub fn stride(&self) -> Vec<usize> {
        let mut ret = vec![0; self.dim.len()];
        let dsize = ret.len();
        for i in 0..dsize {
            if i == 0 {
                ret[dsize-1] = 1;
            } else {
                ret[dsize-i-1] = ret[dsize-i]*self.dim[dsize-i];
            }
        }
        ret
    }
    
    /// Return value at the index of the tensor.
    ///
    /// ```
    /// # use tensor_rs::tensor::gen_tensor::*;
    /// let m1 = GenTensor::<f64>::new_raw(&vec![1.,2.,3.,4.,5.,6.], &vec![2,3]);
    /// assert_eq!(m1.get(&vec![1,1]), 5.);
    /// ```
    pub fn get(&self, o: &[usize]) -> f32 {
        unimplemented!();
    }
    pub fn set(&mut self, o: &[usize], v: f32) {
        unimplemented!();
    }
    pub fn set_1d(&mut self, o: usize, v: f32) {
        unimplemented!();
    }
    pub fn get_mut(&mut self, o: &[usize]) -> &mut f32 {
        unimplemented!();
    }

    /// dump the underlying vec
    pub fn get_raw(&self) -> Vec<f32> {
        unimplemented!();
    }
    pub fn get_u8(&self) -> Option<Vec<u8>> {
        unimplemented!();
    }
    
    /// dump the single value in the tensor
    /// if it is the single value in the tensor.
    pub fn get_scale(&self) -> f32 {
        unimplemented!();
    }

    // get NCHW elements
    /// get NCHW elements, always return the size of left most dimension.
    pub fn get_n(&self) -> CudaTensor {
        CudaTensor::new_raw(&vec![self.dim[0] as f32], &vec![1])
    }
    /// get NCHW elements, always return the size of second left most dimension.
    pub fn get_c(&self) -> CudaTensor {
        CudaTensor::new_raw(&vec![self.dim[1] as f32], &vec![1])
    }
    /// get NCDHW elements, will require the self.dim has 5 dimensions.
    pub fn get_d(&self) -> CudaTensor {
        if self.dim.len() == 5 {
            CudaTensor::new_raw(&vec![self.dim[2] as f32], &vec![1])
        } else {
            panic!("Bad shape for get_D");
        }

    }
    /// get NCDHW elements, will require the self.dim has 5 dimensions or 4 dimensions.
    pub fn get_h(&self) -> CudaTensor {
        if self.dim.len() == 5 {
            CudaTensor::new_raw(&vec![self.dim[3] as f32], &vec![1])
        } else if self.dim.len() == 4 {
            CudaTensor::new_raw(&vec![self.dim[2] as f32], &vec![1])
        } else {
            panic!("Bad shape for get_D");
        }
    }
    /// get NCDHW elements, will require the self.dim has 5 dimensions or 4 dimensions.
    pub fn get_w(&self) -> CudaTensor {
        if self.dim.len() == 5 {
            CudaTensor::new_raw(&vec![self.dim[4] as f32], &vec![1])
        } else if self.dim.len() == 4 {
            CudaTensor::new_raw(&vec![self.dim[3] as f32], &vec![1])
        } else {
            panic!("Bad shape for get_D");
        }
    }

    /// Returns the size of the self tensor.
    pub fn size(&self) -> &Vec<usize> {
        &self.dim
    }
    pub fn get_data(&self) -> &Vec<f32> {
        &self.d
    }
    pub fn get_data_mut(&mut self) -> &mut Vec<f32> {
        &mut self.d
    }

    /// Returns the total number of elements in the input tensor
    pub fn numel(&self) -> usize {
        self.d.len()
    }

    /// Returns the total number of elements in the input tensor
    pub fn numel_tensor(&self) -> CudaTensor {
        CudaTensor::new_raw(&vec![self.d.len() as f32], &vec![1])
    }
}

impl Drop for CudaTensor {
    fn drop(&mut self) {
        if self.device_data != std::ptr::null_mut() {
            unsafe {
                println!("cudaFree");
                check_cuda_status(cudaFree(self.device_data as _));                    
            }
        }
    }
}

impl std::fmt::Debug for CudaTensor {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {

        write!(f, "{:?}\n", self.dim)?;
        write!(f, "{:?}", self.mm_data)

    }
}

//impl<T> Clone for CudaTensor<T> where T: num_traits::Float {
//    fn clone(&self) -> Self {
//        CudaTensor {
//            
//        }
//    }
//}


#[cfg(all(test, feature = "use-cuda"))]
mod tests {
    use super::*;

    #[test]
    fn cuda_memcpy() {
        let mut input = CudaTensor::new_raw(&vec![1., 2., 3., 4., 5., 6., 7., 8., 9.],
                                            &vec![1, 1, 3, 3]);
        input._sync();
        println!("{:?}", input);
    }

}
